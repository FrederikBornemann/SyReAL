{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random</th>\n",
       "      <th>combinatory</th>\n",
       "      <th>std</th>\n",
       "      <th>complexity-std</th>\n",
       "      <th>loss-std</th>\n",
       "      <th>true-confusion</th>\n",
       "      <th>formula</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>II.11.17</th>\n",
       "      <td>[ 7. 21. 15. 17. 21. 43. 41. 25. 14. 25. 11. 2...</td>\n",
       "      <td>[30. 35. 50. 28. 26. 25. 37. 31. 27. 38. 48. 3...</td>\n",
       "      <td>[22. 13. 17. 12. 13. 16. 12. 11. 14. 13. 17. 2...</td>\n",
       "      <td>[10. 18. 19. 11. 17. 19. 10. 19. 18.  6. 18. 1...</td>\n",
       "      <td>[16. 16. 20. 16. 14. 14. 14. 16. 16. 19.  7. 1...</td>\n",
       "      <td>[10. 10. 10.  8. 10. 11.  8.  9. 12.  7. 12. 1...</td>\n",
       "      <td>n_0*(1+p_d*Ef*cos(theta)/(kb*T))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I.24.6</th>\n",
       "      <td>[ nan  26. 115.  nan  nan  78.  nan  nan  nan ...</td>\n",
       "      <td>[169.  29.  49.  93. 158. 227. 292.  43.  56. ...</td>\n",
       "      <td>[254.  84. 178. 166.  73. 197.  19. 135. 180. ...</td>\n",
       "      <td>[ 27. 136.  94. 102. 104. 127.  98.  18.  11. ...</td>\n",
       "      <td>[ 95.  92.  95.  95.  93.  99.  95. 163.  55. ...</td>\n",
       "      <td>[ 69.  71.  80.  63.  24.  47.  60. 110.  nan ...</td>\n",
       "      <td>1/2*m*(omega**2+omega_0**2)*1/2*x**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>II.11.20</th>\n",
       "      <td>[27. 15. 34. 26. 20. 13. 18. 23. 15. 25. 25. 1...</td>\n",
       "      <td>[16. 16. 15. 15.  9. 18. 21. 13. 21. 13. 15. 1...</td>\n",
       "      <td>[17.  9. 18. 18. 12. 17. 14. 13.  7. 13. 12. 1...</td>\n",
       "      <td>[  8.   8.  13.  93. 108. 105. 113. 150.  90. ...</td>\n",
       "      <td>[11. 15. 14. 12. 17. 15. 17. 15. 15. 13. 15. 1...</td>\n",
       "      <td>[14. 11. 10.  9. 10. 10. 13. 14.  9. 14. 10. 1...</td>\n",
       "      <td>n_rho*p_d**2*Ef/(3*kb*T)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>III.13.18</th>\n",
       "      <td>[15. 30.  8.  7. 29. 10. 10. 11. 11. 13. nan 1...</td>\n",
       "      <td>[ 5.  9. 16. 16.  7. 13. 10. 16. 12. 16. 11.  ...</td>\n",
       "      <td>[ 6. 13. 16. 10. 11. 10.  9.  8.  8. 10. 13. 1...</td>\n",
       "      <td>[ 5.  9.  7. 11. 15.  8. 17.  9. 13. 19. 10. 1...</td>\n",
       "      <td>[17. 16.  9. 13. 22. 10. 15.  9.  7. 12.  9. 1...</td>\n",
       "      <td>[ 8.  8.  9.  8. 10. 10.  8.  7.  8. 11. 11. 1...</td>\n",
       "      <td>2*E_n*d**2*k/(h/(2*pi))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I.13.4</th>\n",
       "      <td>[ 39.  17.  59. 205.  32.  51. 112. 265. 280. ...</td>\n",
       "      <td>[ 50.   9.  16.  21.  12.  25.  44.  48.  41. ...</td>\n",
       "      <td>[21. 45. 27. 54. 18. 24. 34. 39. 74. 27. 49. 3...</td>\n",
       "      <td>[ 18.  58.  18.  42.  32.  14. 144.  28.  43. ...</td>\n",
       "      <td>[ 97.  23.  23.  96.  94.  90.  87.  34.  78. ...</td>\n",
       "      <td>[26. 27. 15. 24. 32. 10. 28. 17. 30. 21. 38. 2...</td>\n",
       "      <td>1/2*m*(v**2+u**2+w**2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      random  \\\n",
       "Equation                                                       \n",
       "II.11.17   [ 7. 21. 15. 17. 21. 43. 41. 25. 14. 25. 11. 2...   \n",
       "I.24.6     [ nan  26. 115.  nan  nan  78.  nan  nan  nan ...   \n",
       "II.11.20   [27. 15. 34. 26. 20. 13. 18. 23. 15. 25. 25. 1...   \n",
       "III.13.18  [15. 30.  8.  7. 29. 10. 10. 11. 11. 13. nan 1...   \n",
       "I.13.4     [ 39.  17.  59. 205.  32.  51. 112. 265. 280. ...   \n",
       "\n",
       "                                                 combinatory  \\\n",
       "Equation                                                       \n",
       "II.11.17   [30. 35. 50. 28. 26. 25. 37. 31. 27. 38. 48. 3...   \n",
       "I.24.6     [169.  29.  49.  93. 158. 227. 292.  43.  56. ...   \n",
       "II.11.20   [16. 16. 15. 15.  9. 18. 21. 13. 21. 13. 15. 1...   \n",
       "III.13.18  [ 5.  9. 16. 16.  7. 13. 10. 16. 12. 16. 11.  ...   \n",
       "I.13.4     [ 50.   9.  16.  21.  12.  25.  44.  48.  41. ...   \n",
       "\n",
       "                                                         std  \\\n",
       "Equation                                                       \n",
       "II.11.17   [22. 13. 17. 12. 13. 16. 12. 11. 14. 13. 17. 2...   \n",
       "I.24.6     [254.  84. 178. 166.  73. 197.  19. 135. 180. ...   \n",
       "II.11.20   [17.  9. 18. 18. 12. 17. 14. 13.  7. 13. 12. 1...   \n",
       "III.13.18  [ 6. 13. 16. 10. 11. 10.  9.  8.  8. 10. 13. 1...   \n",
       "I.13.4     [21. 45. 27. 54. 18. 24. 34. 39. 74. 27. 49. 3...   \n",
       "\n",
       "                                              complexity-std  \\\n",
       "Equation                                                       \n",
       "II.11.17   [10. 18. 19. 11. 17. 19. 10. 19. 18.  6. 18. 1...   \n",
       "I.24.6     [ 27. 136.  94. 102. 104. 127.  98.  18.  11. ...   \n",
       "II.11.20   [  8.   8.  13.  93. 108. 105. 113. 150.  90. ...   \n",
       "III.13.18  [ 5.  9.  7. 11. 15.  8. 17.  9. 13. 19. 10. 1...   \n",
       "I.13.4     [ 18.  58.  18.  42.  32.  14. 144.  28.  43. ...   \n",
       "\n",
       "                                                    loss-std  \\\n",
       "Equation                                                       \n",
       "II.11.17   [16. 16. 20. 16. 14. 14. 14. 16. 16. 19.  7. 1...   \n",
       "I.24.6     [ 95.  92.  95.  95.  93.  99.  95. 163.  55. ...   \n",
       "II.11.20   [11. 15. 14. 12. 17. 15. 17. 15. 15. 13. 15. 1...   \n",
       "III.13.18  [17. 16.  9. 13. 22. 10. 15.  9.  7. 12.  9. 1...   \n",
       "I.13.4     [ 97.  23.  23.  96.  94.  90.  87.  34.  78. ...   \n",
       "\n",
       "                                              true-confusion  \\\n",
       "Equation                                                       \n",
       "II.11.17   [10. 10. 10.  8. 10. 11.  8.  9. 12.  7. 12. 1...   \n",
       "I.24.6     [ 69.  71.  80.  63.  24.  47.  60. 110.  nan ...   \n",
       "II.11.20   [14. 11. 10.  9. 10. 10. 13. 14.  9. 14. 10. 1...   \n",
       "III.13.18  [ 8.  8.  9.  8. 10. 10.  8.  7.  8. 11. 11. 1...   \n",
       "I.13.4     [26. 27. 15. 24. 32. 10. 28. 17. 30. 21. 38. 2...   \n",
       "\n",
       "                                        formula  \n",
       "Equation                                         \n",
       "II.11.17       n_0*(1+p_d*Ef*cos(theta)/(kb*T))  \n",
       "I.24.6     1/2*m*(omega**2+omega_0**2)*1/2*x**2  \n",
       "II.11.20               n_rho*p_d**2*Ef/(3*kb*T)  \n",
       "III.13.18               2*E_n*d**2*k/(h/(2*pi))  \n",
       "I.13.4                   1/2*m*(v**2+u**2+w**2)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv file into a pandas dataframe\n",
    "summary_df = pd.read_csv('../data/summary_df.csv', index_col=0)\n",
    "\n",
    "# check the first 5 rows of the dataframe\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/Create the trial summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_summary(save_to_file=True):\n",
    "    \"\"\"Creates a dictionary with the number of finished jobs and average last_n for each equation and algorithm\"\"\"\n",
    "    # read the finished jobs file\n",
    "    with open('../data/finished_jobs.json') as f:\n",
    "        finished_jobs = json.load(f)\n",
    "    # create a dictionary with the number of finished jobs and average last_n for each equation and algorithm\n",
    "    trial_summary = {}\n",
    "    for job in finished_jobs:\n",
    "        # job[0] is the job name, job[1] is the parameters\n",
    "        equation = job[0][0].split(\" \")[1]\n",
    "        algorithm = job[0][1]\n",
    "        trial = job[0][2]\n",
    "        last_n = job[1][\"last_n\"]\n",
    "        try:\n",
    "            converged = job[1][\"converged\"]\n",
    "        except KeyError:\n",
    "            if last_n <=499:\n",
    "                converged = False\n",
    "            else:\n",
    "                converged = True\n",
    "        # if the equation is not in the dictionary, add it\n",
    "        if equation not in trial_summary:\n",
    "            trial_summary[equation] = {}\n",
    "        # if the algorithm is not in the dictionary, add it\n",
    "        if algorithm not in trial_summary[equation]:\n",
    "            trial_summary[equation][algorithm] = {}\n",
    "        # add the last_n to the dictionary for the equation and algorithm if the job converged\n",
    "        trial_summary[equation][algorithm][trial] = last_n if converged else None\n",
    "    if save_to_file:\n",
    "        with open('../data/trial_data.json', \"w\") as f:\n",
    "            json.dump(trial_summary, f)\n",
    "    return trial_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_summary_dict = trial_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the column \"true-confusion\" to \"true-mod\" to be consistent with the other dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column \"true-confusion\" to \"true-mod\"\n",
    "summary_df.rename(columns={'true-confusion': 'true-mod'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-transform the dataframes to have the same format as the original dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_list(string):\n",
    "    \"\"\"Convert a string to a list of floats. Replace 'nan' with np.nan. Return a numpy array.\"\"\"\n",
    "    string = str(string).replace('[', '').replace(']', '').replace('\\n',' ').split(' ')\n",
    "    string = [x for x in string if x != '']\n",
    "    string = [float(i) for i in string]\n",
    "    # replace nan with np.nan\n",
    "    string = [np.nan if x == 'nan' else x for x in string]\n",
    "    # convert to numpy array\n",
    "    string = np.array(string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all columns to list\n",
    "for col in summary_df.columns[:-1]:\n",
    "    summary_df[col] = summary_df[col].apply(str_to_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out the data to only include the columns we need for our analysis. The threshold of minimum number of samples is set as `treshold_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          random  combinatory  std  complexity-std  loss-std  true-mod  \\\n",
      "Equation                                                                 \n",
      "I.24.6        42           98  100              44        12        90   \n",
      "II.35.18      94          100   99              84        48        97   \n",
      "II.21.32      93           17   36              19        25         1   \n",
      "I.50.26        1            1    1               1        59        63   \n",
      "\n",
      "                                             formula  \n",
      "Equation                                              \n",
      "I.24.6          1/2*m*(omega**2+omega_0**2)*1/2*x**2  \n",
      "II.35.18  n_0/(exp(mom*B/(kb*T))+exp(-mom*B/(kb*T)))  \n",
      "II.21.32                  q/(4*pi*epsilon*r*(1-v/c))  \n",
      "I.50.26      x1*(cos(omega*t)+alpha*cos(omega*t)**2)  \n"
     ]
    }
   ],
   "source": [
    "threshold_value = 50 # set the minimum number of samples for the approach at a equation\n",
    "\n",
    "# make a new dataframe with the length of each list\n",
    "summary_df_len = summary_df.copy()\n",
    "for col in summary_df_len.columns[:-1]:\n",
    "    summary_df_len[col] = summary_df_len[col].apply(len)\n",
    "\n",
    "# Define the columns to check\n",
    "columns_to_check = ['random', 'combinatory','std','complexity-std','loss-std','true-mod']\t\n",
    "\n",
    "# Filter and print rows where at least one element in the specified columns is less than the threshold\n",
    "filtered_rows = summary_df_len[(summary_df_len[columns_to_check] < threshold_value).any(axis=1)]\n",
    "print(filtered_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe shape: (42, 7)\n",
      "Filtered dataframe shape: (38, 7)\n"
     ]
    }
   ],
   "source": [
    "# create a new dataframe without the filtered rows\n",
    "summary_df_filtered = summary_df[~summary_df.index.isin(filtered_rows.index)]\n",
    "# print the shape of the original and filtered dataframe\n",
    "print(f\"Original dataframe shape: {summary_df.shape}\")\n",
    "print(f\"Filtered dataframe shape: {summary_df_filtered.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Dokumente\\GitHub\\SyReAL\\notebooks\\data_analysis.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dokumente/GitHub/SyReAL/notebooks/data_analysis.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dokumente/GitHub/SyReAL/notebooks/data_analysis.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# plot the correlation between the columns 'random' and 'combinatory'\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Dokumente/GitHub/SyReAL/notebooks/data_analysis.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m correlation_plot_of_columns(summary_df_filtered, \u001b[39m'\u001b[39;49m\u001b[39mrandom\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcombinatory\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32md:\\Dokumente\\GitHub\\SyReAL\\notebooks\\data_analysis.ipynb Cell 20\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dokumente/GitHub/SyReAL/notebooks/data_analysis.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df_corr \u001b[39m=\u001b[39m df_corr\u001b[39m.\u001b[39mdropna()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dokumente/GitHub/SyReAL/notebooks/data_analysis.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# compute the correlation matrix\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dokumente/GitHub/SyReAL/notebooks/data_analysis.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m corr \u001b[39m=\u001b[39m df_corr\u001b[39m.\u001b[39;49mcorr()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dokumente/GitHub/SyReAL/notebooks/data_analysis.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# plot the correlation matrix\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dokumente/GitHub/SyReAL/notebooks/data_analysis.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m sns\u001b[39m.\u001b[39mheatmap(corr, annot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBlues\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Dokumente\\GitHub\\SyReAL\\.conda\\lib\\site-packages\\pandas\\core\\frame.py:10707\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  10705\u001b[0m cols \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m  10706\u001b[0m idx \u001b[39m=\u001b[39m cols\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m> 10707\u001b[0m mat \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mto_numpy(dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m, na_value\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mnan, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m  10709\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m  10710\u001b[0m     correl \u001b[39m=\u001b[39m libalgos\u001b[39m.\u001b[39mnancorr(mat, minp\u001b[39m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32md:\\Dokumente\\GitHub\\SyReAL\\.conda\\lib\\site-packages\\pandas\\core\\frame.py:1892\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1891\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1892\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[0;32m   1893\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m dtype:\n\u001b[0;32m   1894\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Dokumente\\GitHub\\SyReAL\\.conda\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1650\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1644\u001b[0m     arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mto_numpy(  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1645\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1646\u001b[0m         na_value\u001b[39m=\u001b[39mna_value,\n\u001b[0;32m   1647\u001b[0m         copy\u001b[39m=\u001b[39mcopy,\n\u001b[0;32m   1648\u001b[0m     )\u001b[39m.\u001b[39mreshape(blk\u001b[39m.\u001b[39mshape)\n\u001b[0;32m   1649\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1650\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(blk\u001b[39m.\u001b[39;49mvalues, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m   1652\u001b[0m \u001b[39mif\u001b[39;00m using_copy_on_write() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m copy:\n\u001b[0;32m   1653\u001b[0m     arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "def correlation_plot_of_columns(df, col1, col2):\n",
    "    \"\"\"Plot the correlation between two columns of a dataframe.\"\"\"\n",
    "    # create a dataframe with the two columns\n",
    "    df_corr = df[[col1, col2]]\n",
    "    # drop rows with missing values\n",
    "    df_corr = df_corr.dropna()\n",
    "    # compute the correlation matrix\n",
    "    corr = df_corr.corr()\n",
    "    # plot the correlation matrix\n",
    "    sns.heatmap(corr, annot=True, cmap='Blues')\n",
    "    plt.show()\n",
    "\n",
    "# plot the correlation between the columns 'random' and 'combinatory'\n",
    "correlation_plot_of_columns(summary_df_filtered, 'random', 'combinatory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
